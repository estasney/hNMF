{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"hNMF","text":"<p>hNMF implements Rank-2 NMF for Hierarchical Clustering as described in this paper and repository.</p> <p>hNMF is a fork of hierarchical-nmf-python with several modifications:</p> <ul> <li>Interface to hNMF is provided with a scikit-learn compatible BaseEstimator</li> <li>Improved performance timings</li> <li>Convenience methods for interpreting results</li> </ul>"},{"location":"#performance","title":"Performance","text":"<p>The paper mentions that the hierarchical NMF process takes advantage of a fast 2-rank matrix decomposition, While this may be true in MATLAB, the original Python implementation was significantly bottlenecked when running the 2-rank decomposition.</p>"},{"location":"#citations","title":"Citations","text":"<p>[1] Da Kuang, Haesun Park, Fast rank-2 nonnegative matrix factorization for hierarchical document clustering, The 19th ACM SIGKDD International Conference on Knowledge, Discovery, and Data Mining (KDD '13), pp. 739-747, 2013.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#hnmfmodel","title":"hNMF.model","text":""},{"location":"api/#hnmf.model.HierarchicalNMF","title":"<code>hnmf.model.HierarchicalNMF(k, unbalanced=0.1, init=None, solver='cd', beta_loss=0, alpha_W=0.0, alpha_H='same', random_state=42, trial_allowance=100, tol=1e-06, maxiter=10000, dtype=np.float64)</code>","text":"<p>               Bases: <code>BaseEstimator</code></p> <p>Methods:</p> Name Description <code>_init_fit</code> <code>_stack_H_buffer</code> <code>_stack_clusters</code> <code>cluster_assignments</code> <p>Returns a mapping of features and their assigned cluster(s)</p> <code>cluster_features</code> <p>Returns the features assigned as a cluster to nodes</p> <code>fit</code> <p>Fit <code>HierarchicalNMF</code> to data</p> <code>top_discriminative_samples_in_node</code> <p>Computes most discriminative samples (node vs rest)</p> <code>top_features_in_node</code> <p>For a given node, return the top n features and values</p> <code>top_nodes_in_feature</code> <p>Returns the top nodes for a specified feature</p> <code>top_nodes_in_samples</code> <p>Returns the top nodes for each sample.</p> <code>top_samples_in_nodes</code> <p>Returns the top samples for each node</p> <p>Attributes:</p> Name Type Description <code>H_buffer_</code> <code>NDArray | None</code> <code>Hs_</code> <code>NDArray | None</code> <code>W_buffer_</code> <code>NDArray | None</code> <code>Ws_</code> <code>NDArray | None</code> <code>alpha_H</code> <code>Literal['same'] | float</code> <code>alpha_W</code> <code>float</code> <code>beta_loss</code> <code>Literal['FRO', 0, 'KL', 1, 'IS', 2]</code> <code>clusters_</code> <code>NDArray | None</code> <code>dtype</code> <code>DTypeLike</code> <code>feature2id_</code> <code>dict[str, int] | None</code> <code>id2feature_</code> <code>dict[int, str] | None</code> <code>id2sample_</code> <code>dict[int, str] | None</code> <code>init</code> <code>Literal[None, 'random', 'nndsvd', 'nndsvda', 'nndsvdar']</code> <code>is_leaf_</code> <code>NDArray | None</code> <code>k</code> <code>int</code> <code>maxiter</code> <code>int</code> <code>n_features_</code> <code>int | None</code> <code>n_leaves_</code> <code>int</code> <code>n_nodes_</code> <code>int</code> <code>n_samples_</code> <code>int | None</code> <code>priorities_</code> <code>NDArray | None</code> <code>random_state</code> <code>RandomState</code> <code>solver</code> <code>Literal['cd', 'mu']</code> <code>splits_</code> <code>NDArray | None</code> <code>tol</code> <code>float</code> <code>tree_</code> <code>NDArray | None</code> <code>trial_allowance</code> <code>int</code> <code>unbalanced</code> <code>float</code> Source code in <code>src/hnmf/model.py</code> <pre><code>def __init__(\n    self,\n    k: int,\n    unbalanced: float = 0.1,\n    init: Literal[None, \"random\", \"nndsvd\", \"nndsvda\", \"nndsvdar\"] = None,\n    solver: Literal[\"cd\", \"mu\"] = \"cd\",\n    beta_loss: Literal[\"FRO\", 0, \"KL\", 1, \"IS\", 2] = 0,\n    alpha_W: float = 0.0,\n    alpha_H: Literal[\"same\"] | float = \"same\",\n    random_state: int = 42,\n    trial_allowance: int = 100,\n    tol: float = 1e-6,\n    maxiter: int = 10000,\n    dtype: npt.DTypeLike = np.float64,\n):\n    self.k = k\n    self.unbalanced = unbalanced\n    self.init = init\n    self.solver = solver\n    self.beta_loss = beta_loss\n    self.alpha_W = alpha_W\n    self.alpha_H = alpha_H\n    self.random_state = np.random.RandomState(seed=random_state)\n    self.trial_allowance = trial_allowance\n    self.tol = tol\n    self.maxiter = maxiter\n    self.dtype = dtype\n\n    self.n_samples_ = None\n    self.n_features_ = None\n    self.n_nodes_ = 0\n    self.n_leaves_ = 0\n    self.tree_ = None\n    self.splits_ = None\n    self.is_leaf_ = None\n    self.clusters_ = None\n    self.Ws_ = None\n    self.Hs_ = None\n    self.W_buffer_ = None\n    self.H_buffer_ = None\n    self.priorities_ = None\n    self.id2sample_ = None\n    self.id2feature_ = None\n    self.feature2id_ = None\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.H_buffer_","title":"<code>H_buffer_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.Hs_","title":"<code>Hs_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.W_buffer_","title":"<code>W_buffer_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.Ws_","title":"<code>Ws_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.alpha_H","title":"<code>alpha_H = alpha_H</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.alpha_W","title":"<code>alpha_W = alpha_W</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.beta_loss","title":"<code>beta_loss = beta_loss</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.clusters_","title":"<code>clusters_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.dtype","title":"<code>dtype = dtype</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.feature2id_","title":"<code>feature2id_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.id2feature_","title":"<code>id2feature_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.id2sample_","title":"<code>id2sample_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.init","title":"<code>init = init</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.is_leaf_","title":"<code>is_leaf_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.k","title":"<code>k = k</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.maxiter","title":"<code>maxiter = maxiter</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.n_features_","title":"<code>n_features_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.n_leaves_","title":"<code>n_leaves_ = 0</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.n_nodes_","title":"<code>n_nodes_ = 0</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.n_samples_","title":"<code>n_samples_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.priorities_","title":"<code>priorities_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.random_state","title":"<code>random_state = np.random.RandomState(seed=random_state)</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.solver","title":"<code>solver = solver</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.splits_","title":"<code>splits_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.tol","title":"<code>tol = tol</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.tree_","title":"<code>tree_ = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.trial_allowance","title":"<code>trial_allowance = trial_allowance</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF.unbalanced","title":"<code>unbalanced = unbalanced</code>  <code>instance-attribute</code>","text":""},{"location":"api/#hnmf.model.HierarchicalNMF._init_fit","title":"<code>_init_fit(X, term_subset)</code>","text":"Source code in <code>src/hnmf/model.py</code> <pre><code>def _init_fit(\n    self, X: npt.NDArray, term_subset: npt.NDArray\n) -&gt; tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]:\n    if not self.n_samples_:\n        raise ValueError(\"n_samples_ not set before _init_fit called\")\n\n    nmf = NMF(\n        n_components=2,\n        random_state=self.random_state,\n        tol=self.tol,\n        max_iter=self.maxiter,\n        init=self.init,\n    )\n\n    if len(term_subset) == self.n_samples_:\n        W = nmf.fit_transform(X)\n        H = nmf.components_\n        return W, H\n\n    W_tmp = nmf.fit_transform(X[term_subset, :])\n    H = nmf.components_\n    W = np.zeros((self.n_samples_, 2), dtype=self.dtype)\n    W[term_subset, :] = W_tmp\n\n    return W, H\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF._stack_H_buffer","title":"<code>_stack_H_buffer(buffer)</code>","text":"Source code in <code>src/hnmf/model.py</code> <pre><code>def _stack_H_buffer(self, buffer: list) -&gt; npt.NDArray:\n    if self.n_features_ is None:\n        raise ValueError(\"n_features_ not set before _stack_H_buffer called\")\n    if self.clusters_ is None:\n        raise ValueError(\"clusters_ not set before _stack_H_buffer called\")\n\n    result = np.zeros((len(buffer), 2, self.n_features_), dtype=self.dtype)\n    for i, buff in enumerate(buffer):\n        cluster_nz_idx = np.argwhere(self.clusters_[i]).flatten()\n        result[i, 0, cluster_nz_idx] = buff[0, :]\n        result[i, 1, cluster_nz_idx] = buff[1, :]\n    return result\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF._stack_clusters","title":"<code>_stack_clusters(clusters)</code>","text":"Source code in <code>src/hnmf/model.py</code> <pre><code>def _stack_clusters(self, clusters: list[npt.NDArray | None]) -&gt; npt.NDArray:\n    if not self.n_features_:\n        raise ValueError(\"n_features_ not set before _stack_clusters called\")\n    result = np.zeros((len(clusters), self.n_features_), dtype=np.int64)\n    for i, cluster in enumerate(clusters):\n        result[i, cluster] = 1\n    return result\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.cluster_assignments","title":"<code>cluster_assignments(leaves_only=True, include_outliers=True)</code>","text":"<p>Returns a mapping of features and their assigned cluster(s)</p> <p>Parameters:</p> Name Type Description Default <code>leaves_only</code> <code>bool</code> <p>Whether to return only leaf nodes</p> <code>True</code> <code>include_outliers</code> <code>bool</code> <p>If True, include feature_idx keys that are not assigned a cluster.</p> <code>True</code> Source code in <code>src/hnmf/model.py</code> <pre><code>def cluster_assignments(\n    self,\n    leaves_only: bool = True,\n    include_outliers: bool = True,\n) -&gt; dict[int, set[int]]:\n    \"\"\"\n    Returns a mapping of features and their assigned cluster(s)\n\n    Parameters\n    ----------\n    leaves_only\n        Whether to return only leaf nodes\n    include_outliers\n        If True, include feature_idx keys that are not assigned a cluster.\n\n    \"\"\"\n\n    if self.clusters_ is None:\n        raise ValueError(\"Model not fitted, clusters_ is None\")\n\n    node_leaf_idx = np.where(self.is_leaf_ == 1)[0]\n\n    clusters = self.clusters_\n    output = defaultdict(set)\n    assignments = np.argwhere(clusters)\n    if leaves_only:\n        assignments = assignments[\n            np.where(np.isin(assignments[:, 0], node_leaf_idx))[0]\n        ]\n\n    for cluster_idx, feature_idx in assignments:\n        output[cluster_idx].add(feature_idx)\n\n    if include_outliers:\n        outliers = np.where(clusters.sum(axis=0) == 0)[0]\n        for outlier in outliers:\n            output[outlier] = set()\n\n    return dict(output)\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.cluster_features","title":"<code>cluster_features(leaves_only=True, include_outliers=True)</code>","text":"<p>Returns the features assigned as a cluster to nodes</p> <p>Parameters:</p> Name Type Description Default <code>leaves_only</code> <code>bool</code> <p>Whether to return only leaf nodes</p> <code>True</code> <code>include_outliers</code> <code>bool</code> <p>If True, features without a node assignment are returned under the key -1</p> <code>True</code> Source code in <code>src/hnmf/model.py</code> <pre><code>def cluster_features(\n    self,\n    leaves_only: bool = True,\n    include_outliers: bool = True,\n) -&gt; dict[int, list[int]]:\n    \"\"\"\n    Returns the features assigned as a cluster to nodes\n\n    Parameters\n    ----------\n    leaves_only\n        Whether to return only leaf nodes\n    include_outliers\n        If True, features without a node assignment are returned under the key -1\n\n    \"\"\"\n\n    if self.clusters_ is None:\n        raise ValueError(\"Model not fitted, clusters_ is None\")\n\n    output = defaultdict(list)\n\n    node_leaf_idx = np.where(self.is_leaf_ == 1)[0]\n\n    clusters = self.clusters_[node_leaf_idx] if leaves_only else self.clusters_\n\n    assignments = np.argwhere(clusters)\n\n    for cluster_idx, feature_idx in assignments:\n        output[cluster_idx].append(feature_idx)\n\n    if include_outliers:\n        outliers = np.where(clusters.sum(axis=0) == 0)[0]\n        output[-1] = outliers\n\n    return dict(output)\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.fit","title":"<code>fit(X)</code>","text":"<p>Fit <code>HierarchicalNMF</code> to data</p> Source code in <code>src/hnmf/model.py</code> <pre><code>def fit(self, X: npt.NDArray) -&gt; Self:\n    \"\"\"\n    Fit `HierarchicalNMF` to data\n    \"\"\"\n    shape: tuple[int, int] = X.shape\n    n_samples, n_features = shape\n    self.n_samples_ = n_samples\n    self.n_features_ = n_features\n\n    # TODO Expect different sized ranks\n    clusters: list[npt.NDArray[np.int64] | None] = [None] * (2 * (self.k - 1))\n    Ws = [None] * (2 * (self.k - 1))\n    Hs = [None] * (2 * (self.k - 1))\n    W_buffer = [None] * (2 * (self.k - 1))\n    H_buffer = [None] * (2 * (self.k - 1))\n    priorities = np.zeros(2 * (self.k - 1), dtype=self.dtype)\n    is_leaf = np.zeros(2 * (self.k - 1), dtype=np.bool)  # No leaves at start\n    tree = np.zeros((2, 2 * (self.k - 1)), dtype=np.int64)\n    splits = -np.ones(self.k - 1, dtype=np.int64)\n\n    # Where X has at least one non-zero\n    term_subset = np.flatnonzero(np.sum(X, axis=1))\n\n    W, H = self._init_fit(X, term_subset)\n\n    result_used = 0\n\n    with ProgressTree() as pt:\n        for i in range(self.k - 1):\n            if i == 0:\n                split_node = 0\n                new_nodes = [0, 1]\n                min_priority = 1e40\n                split_subset = np.arange(n_features)\n            else:\n                leaves = np.where(is_leaf == 1)[0]\n                temp_priority = priorities[leaves]\n\n                if len(np.where(temp_priority &gt; 0)[0]) &gt; 0:\n                    min_priority = np.min(temp_priority[temp_priority &gt; 0])\n                    split_node = np.argmax(temp_priority)\n                else:  # There are no more candidates stop early\n                    min_priority = -1\n                    split_node = 0\n\n                if temp_priority[split_node] &lt; 0 or min_priority == -1:\n                    logger.warning(\n                        f\"Cannot generate all {self.k} leaf clusters, stopping at {i} leaf clusters\"\n                    )\n\n                    Ws = [i for i in Ws if i is not None]\n                    W_buffer = [i for i in W_buffer if i is not None]\n\n                    Hs = [i for i in Hs if i is not None]\n                    H_buffer = [i for i in H_buffer if i is not None]\n\n                    # Resize attributes\n                    tree = tree[:, :result_used]\n                    splits = splits[:result_used]\n                    is_leaf = is_leaf[:result_used]\n                    clusters = clusters[:result_used]\n                    priorities = priorities[:result_used]\n\n                    self.tree_ = tree.T\n                    self.splits_ = splits\n                    self.is_leaf_ = is_leaf\n                    self.n_nodes_ = self.is_leaf_.shape[0]\n                    self.n_leaves_ = int(np.count_nonzero(self.is_leaf_))\n                    self.clusters_ = self._stack_clusters(clusters)\n                    self.Ws_ = np.array(Ws)\n                    self.Hs_ = np.array(Hs)\n                    self.W_buffer_ = np.array(W_buffer)\n                    self.H_buffer_ = self._stack_H_buffer(H_buffer)\n                    self.priorities_ = priorities\n                    return self\n\n                split_node = leaves[split_node]  # Attempt to split this node\n                is_leaf[split_node] = 0\n                W = W_buffer[split_node]\n                H = H_buffer[split_node]\n\n                # Find which features are clustered on this node\n                split_subset = clusters[split_node]\n                new_nodes = [result_used, result_used + 1]\n                tree[:, split_node] = new_nodes\n\n            result_used += 2\n            # For each row find where it is more greatly represented\n            cluster_subset = np.argmax(H, axis=0)\n\n            subset_0 = np.flatnonzero(cluster_subset == 0)\n            subset_1 = np.flatnonzero(cluster_subset == 1)\n            ls0 = len(subset_0)\n            ls1 = len(subset_1)\n\n            if i == 0:\n                pt.add_branch(\"Root\", new_nodes[0], ls0)\n                pt.add_branch(\"Root\", new_nodes[1], ls1)\n            else:\n                pt.add_branch(split_node, new_nodes[0], ls0)\n                pt.add_branch(split_node, new_nodes[1], ls1)\n\n            clusters[new_nodes[0]] = split_subset[subset_0]\n            clusters[new_nodes[1]] = split_subset[subset_1]\n            Ws[new_nodes[0]] = W[:, 0]\n            Ws[new_nodes[1]] = W[:, 1]\n\n            # These will not have shape of (2, n_features) because they are fitting a subset\n            # Create zero filled array of shape (2, n_features)\n            h_temp = np.zeros(shape=(2, self.n_features_), dtype=self.dtype)\n            # Which features are present in H\n\n            h_temp[0, split_subset] = H[0]\n            h_temp[1, split_subset] = H[1]\n\n            Hs[new_nodes[0]] = h_temp[0]\n            Hs[new_nodes[1]] = h_temp[1]\n\n            splits[i] = split_node\n            is_leaf[new_nodes] = 1\n\n            subset = clusters[new_nodes[0]]\n            (\n                subset,\n                W_buffer_one,\n                H_buffer_one,\n                priority_one,\n            ) = trial_split_sklearn(\n                min_priority=min_priority,\n                X=X,\n                subset=subset,\n                W_parent=W[:, 0],\n                random_state=self.random_state,\n                trial_allowance=self.trial_allowance,\n                unbalanced=self.unbalanced,\n                dtype=self.dtype,\n                tol=self.tol,\n                maxiter=self.maxiter,\n                init=self.init,\n                alpha_W=self.alpha_W,\n                alpha_H=self.alpha_H,\n            )\n            clusters[new_nodes[0]] = subset\n            W_buffer[new_nodes[0]] = W_buffer_one\n            H_buffer[new_nodes[0]] = H_buffer_one\n            priorities[new_nodes[0]] = priority_one\n\n            subset = clusters[new_nodes[1]]\n            (\n                subset,\n                W_buffer_one,\n                H_buffer_one,\n                priority_one,\n            ) = trial_split_sklearn(\n                min_priority=min_priority,\n                X=X,\n                subset=subset,\n                W_parent=W[:, 1],\n                random_state=self.random_state,\n                trial_allowance=self.trial_allowance,\n                unbalanced=self.unbalanced,\n                dtype=self.dtype,\n                tol=self.tol,\n                maxiter=self.maxiter,\n                init=self.init,\n                alpha_W=self.alpha_W,\n                alpha_H=self.alpha_H,\n            )\n            clusters[new_nodes[1]] = subset\n            W_buffer[new_nodes[1]] = W_buffer_one\n            H_buffer[new_nodes[1]] = H_buffer_one\n            priorities[new_nodes[1]] = priority_one\n    self.tree_ = tree.T\n    self.splits_ = splits\n    self.is_leaf_ = is_leaf\n    self.clusters_ = self._stack_clusters(clusters)\n    self.Ws_ = np.array(Ws)\n    self.Hs_ = np.array(Hs)\n    self.W_buffer_ = np.array(W_buffer)\n    self.H_buffer_ = self._stack_H_buffer(H_buffer)\n    self.priorities_ = priorities\n    self.n_nodes_ = self.is_leaf_.shape[0]\n    self.n_leaves_ = int(np.count_nonzero(self.is_leaf_))\n    return self\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.top_discriminative_samples_in_node","title":"<code>top_discriminative_samples_in_node(node, n=10, sign='abs')</code>","text":"<p>Computes most discriminative samples (node vs rest)</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>int</code> required <code>n</code> <code>int</code> <p>The number of features to return</p> <code>10</code> <code>sign</code> <code>Literal['positive', 'negative', 'abs']</code> <p>One of <code>['positive', 'negative', 'abs']</code>.</p> <code>'abs'</code> <p>Returns:</p> Type Description <code>list of dict with form::</code> <p>sample: Any node: int node_value: float others_value: float</p> Source code in <code>src/hnmf/model.py</code> <pre><code>def top_discriminative_samples_in_node(\n    self,\n    node: int,\n    n: int = 10,\n    sign: Literal[\"positive\", \"negative\", \"abs\"] = \"abs\",\n) -&gt; \"list[DiscriminatedSample]\":\n    \"\"\"\n    Computes most discriminative samples (node vs rest)\n\n    Parameters\n    ----------\n    node\n    n\n        The number of features to return\n    sign\n        One of `['positive', 'negative', 'abs']`.\n\n    Returns\n    --------\n    list of dict with form::\n\n        sample: Any\n        node: int\n        node_value: float\n        others_value: float\n\n    \"\"\"\n\n    if self.Ws_ is None:\n        raise ValueError(\"Model not fitted, Ws_ is None\")\n    if sign not in (\"positive\", \"negative\", \"abs\"):\n        raise ValueError(\"Sign must be one of 'positive', 'negative' or 'abs'\")\n\n    # Masks\n    member_mask = np.array(node, dtype=np.int64)\n    non_member_mask = np.array(\n        [x for x in np.arange(0, self.n_nodes_) if x != node]\n    )\n\n    member_values = self.Ws_[member_mask].ravel()\n    other_means = self.Ws_[non_member_mask].mean(axis=0)\n\n    diffs = (\n        np.abs(member_values - other_means)\n        if sign == \"positive\"\n        else member_values - other_means\n        if sign == \"positive\"\n        else other_means - member_values\n    )\n\n    diff_tops = diffs.argsort()[::-1][:n]\n\n    return [\n        DiscriminatedSample(\n            sample=diff,\n            node=node,\n            node_value=member_values[diff],\n            others_value=other_means[diff],\n        )\n        for diff in diff_tops\n    ]\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.top_features_in_node","title":"<code>top_features_in_node(node, n=10)</code>","text":"<p>For a given node, return the top n features and values</p> Source code in <code>src/hnmf/model.py</code> <pre><code>def top_features_in_node(self, node: int, n: int = 10) -&gt; list[tuple]:\n    \"\"\"\n    For a given node, return the top n features and values\n    \"\"\"\n\n    if self.Hs_ is None:\n        raise ValueError(\"Model not fitted, Hs_ is None\")\n\n    node_i = self.Hs_[node]\n    ranks = node_i.argsort()[::-1][:n]\n    return [(i, node_i[i]) for i in ranks if node_i[i] &gt; 0]\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.top_nodes_in_feature","title":"<code>top_nodes_in_feature(feature_idx, n=10, leaves_only=True)</code>","text":"<p>Returns the top nodes for a specified feature</p> Source code in <code>src/hnmf/model.py</code> <pre><code>def top_nodes_in_feature(\n    self,\n    feature_idx: int | str,\n    n: int = 10,\n    leaves_only: bool = True,\n) -&gt; list[tuple]:\n    \"\"\"\n    Returns the top nodes for a specified feature\n    \"\"\"\n    if self.Hs_ is None:\n        raise ValueError(\"Model not fitted, Hs_ is None\")\n\n    node_leaf_idx = np.where(self.is_leaf_ == 1)[0]\n    node_weights = self.Hs_.T[feature_idx]\n    ranks = node_weights.argsort()[::-1]\n    if leaves_only:\n        ranks = ranks[np.isin(ranks, node_leaf_idx)]\n\n    ranks = ranks[:n]\n\n    return [(i, node_weights[i]) for i in ranks if node_weights[i] &gt; 0]\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.top_nodes_in_samples","title":"<code>top_nodes_in_samples(n=10, leaves_only=True)</code>","text":"<p>Returns the top nodes for each sample.</p> Source code in <code>src/hnmf/model.py</code> <pre><code>def top_nodes_in_samples(self, n: int = 10, leaves_only: bool = True):\n    \"\"\"\n    Returns the top nodes for each sample.\n    \"\"\"\n\n    if self.Ws_ is None or self.n_nodes_ is None:\n        raise ValueError(\"Model not fitted, Ws_ is None\")\n\n    # Idx of leaves\n    node_leaf_idx = np.where(self.is_leaf_ == 1)[0]\n    # Keep map of enumerated -&gt; actual cluster\n    if leaves_only:\n        node_map = dict(enumerate(node_leaf_idx))\n    else:\n        node_map = dict(enumerate(range(self.n_nodes_)))\n\n    # A dictionary of {sample : [top_nodes]}\n\n    output = {}\n\n    # Ws_ is shape n_nodes, n_samples\n    # Transpose weights so it has samples as rows, nodes as columns\n\n    weights = self.Ws_.T[node_leaf_idx].T if leaves_only else self.Ws_.T\n\n    # The ellipsis indicates that the selection is done row wise\n    sample_tops = weights.argsort()[:, ::-1][:, :n]\n\n    # Create an array with samples as rows, top n weights as columns\n    sample_top_weights = np.take_along_axis(weights, sample_tops, axis=1)\n\n    for sample_idx, (node_ids, node_weights) in enumerate(\n        zip(sample_tops, sample_top_weights, strict=True)\n    ):\n        tops = [\n            (node_map[node_id], weight)\n            for node_id, weight in zip(node_ids, node_weights, strict=True)\n            if weight &gt; 0\n        ]\n        tops.sort(key=itemgetter(1), reverse=True)\n        output[sample_idx] = tops\n\n    return output\n</code></pre>"},{"location":"api/#hnmf.model.HierarchicalNMF.top_samples_in_nodes","title":"<code>top_samples_in_nodes(n=10, leaves_only=True)</code>","text":"<p>Returns the top samples for each node</p> Source code in <code>src/hnmf/model.py</code> <pre><code>def top_samples_in_nodes(self, n: int = 10, leaves_only: bool = True):\n    \"\"\"\n    Returns the top samples for each node\n    \"\"\"\n\n    if self.Ws_ is None:\n        raise ValueError(\"Model not fitted, Ws_ is None\")\n\n    # Idx of leaves\n    node_leaf_idx = np.where(self.is_leaf_ == 1)[0]\n\n    # A dictionary of {nodes : [sample]}\n\n    output = {}\n\n    # Ws_ is shape n_nodes, n_samples\n\n    weights = self.Ws_\n\n    # The ellipsis indicates that the selection is done row wise\n    node_tops = weights.argsort()[:, ::-1][:, :n]\n\n    # Create an array with samples as rows, top n weights as columns\n    node_top_weights = np.take_along_axis(weights, node_tops, axis=1)\n\n    for node_idx, (sample_ids, sample_weights) in enumerate(\n        zip(node_tops, node_top_weights, strict=True)\n    ):\n        if leaves_only and node_idx not in node_leaf_idx:\n            continue\n        tops = [\n            (sample_id, weight)\n            for sample_id, weight in zip(sample_ids, sample_weights, strict=True)\n            if weight &gt; 0\n        ]\n        tops.sort(key=itemgetter(1), reverse=True)\n        # Decode samples if available\n\n        output[node_idx] = tops\n\n    return output\n</code></pre>"},{"location":"api/#hnmfhelpers","title":"hNMF.helpers","text":""},{"location":"api/#hnmf.helpers","title":"<code>hnmf.helpers</code>","text":""},{"location":"api/#hnmf.helpers.nmfsh_comb_rank2","title":"<code>nmfsh_comb_rank2(A, Winit, Hinit, anls_alg, vec_norm, normW, tol, maxiter, dtype)</code>","text":"Source code in <code>src/hnmf/helpers.py</code> <pre><code>def nmfsh_comb_rank2(\n    A: npt.NDArray,\n    Winit: npt.NDArray,\n    Hinit: npt.NDArray,\n    anls_alg: AnlsAlgorithm,\n    vec_norm: float,\n    normW: bool,\n    tol: float,\n    maxiter: int,\n    dtype: npt.DTypeLike,\n) -&gt; tuple[npt.NDArray, npt.NDArray]:\n    \"\"\"\"\"\"\n    eps = 1e-6\n    shape: tuple[int, int] = A.shape\n    m, n = shape\n    W, H = Winit, Hinit\n\n    if W.shape[1] != 2:\n        warnings.warn(\n            f\"Error: Wrong size of W! Expected shape of (n, 2) but received W of shape ({W.shape[0]}, {W.shape[1]})\",\n            stacklevel=2,\n        )\n\n    if H.shape[0] != 2:\n        warnings.warn(\n            f\"Error: Wrong size of H! Expected shape of (2, n) but received H of shape ({H.shape[0]}, {H.shape[1]})\",\n            stacklevel=2,\n        )\n\n    left = H.dot(H.T)\n    right = A.dot(H.T)\n    for iter_ in range(maxiter):\n        if matrix_rank(left) &lt; 2:\n            W = np.zeros((m, 2), dtype=dtype)\n            H = np.zeros((2, n), dtype=dtype)\n            if sp.issparse(A):\n                U, _S, V = svd(A.toarray(), full_matrices=False)  # type: ignore[attr-defined]  # A can be sparse\n            else:\n                U, _S, V = svd(A, full_matrices=False)\n            U, V = U[:, 0], V[0, :]\n            if sum(U) &lt; 0:\n                U, V = -U, -V\n\n            W[:, 0] = U\n            H[0, :] = V\n\n            return W, H\n\n        W = anls_alg(left, right, W, dtype)\n        norms_W = norm(W, axis=0)\n        if np.min(norms_W) &lt; eps:\n            logger.warning(\"Error: Some column of W is essentially zero\")\n\n        W *= 1.0 / norms_W\n        left = W.T.dot(W)\n        right = A.T.dot(W)\n        if matrix_rank(left) &lt; 2:\n            W = np.zeros((m, 2), dtype=dtype)\n            H = np.zeros((2, n), dtype=dtype)\n            if sp.issparse(A):\n                U, _S, V = svd(A.toarray(), full_matrices=False)  # type: ignore[attr-defined]  # A can be sparse\n            else:\n                U, _S, V = svd(A, full_matrices=False)\n            U, V = U[:, 0], V[0, :]\n            if sum(U) &lt; 0:\n                U, V = -U, -V\n\n            W[:, 0] = U\n            H[0, :] = V\n\n            return W, H\n\n        H = anls_alg(left, right, H.T, dtype).T\n        gradH = left.dot(H) - right.T\n        left = H.dot(H.T)\n        right = A.dot(H.T)\n        gradW = W.dot(left) - right\n        initgrad = 1\n        if iter_ == 0:\n            gradW_square = np.sum(np.power(gradW[np.logical_or(gradW &lt;= 0, W &gt; 0)], 2))\n            gradH_square = np.sum(np.power(gradH[np.logical_or(gradH &lt;= 0, H &gt; 0)], 2))\n            initgrad = np.sqrt(gradW_square + gradH_square)\n            continue\n        gradW_square = np.sum(np.power(gradW[np.logical_or(gradW &lt;= 0, W &gt; 0)], 2))\n        gradH_square = np.sum(np.power(gradH[np.logical_or(gradH &lt;= 0, H &gt; 0)], 2))\n        projnorm = np.sqrt(gradW_square + gradH_square)\n\n        if projnorm &lt; tol * initgrad:\n            break\n\n    if vec_norm != 0:\n        if normW:\n            norms = np.power(np.sum(np.power(W, vec_norm), axis=0), 1 / vec_norm)\n            W /= norms\n            H *= norms[:, None]\n        else:\n            norms = np.power(np.sum(np.power(H, vec_norm), axis=1), 1 / vec_norm)\n            W *= norms[None, :]\n            H /= norms\n\n    return W, H\n</code></pre>"}]}